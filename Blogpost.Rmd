---
title: "Blogpost"
author: "Group 15: Ruiying Yang, Lukas Zeiz"
date: "28 Juni 2021"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = F,
                      message = FALSE)
```

```{r include=FALSE}
getwd()
```

```{r include=FALSE}
rm(list = ls())  

library(pacman)
library("RColorBrewer")
p_load(ggplot2,    
       cowplot,   
       stargazer, 
       glmnet,    
       pROC,      
       caret,       
       rpart,        
       rpart.plot,
       moments)

spam <- read.csv("spam7.csv", sep = ",", stringsAsFactors = T, header = T)
```
## Description of the Dataset:
Our topic is spam email data and our task is to predict whether an email is a spam or not. The data consist of 4601 email items, of which 1813 items were identified as spam. There are 6 prediators, which are the following:
* the total length of words in capitals (crl.tot)
* the number of occurrences of the \$ symbol (dollar)
* the number of occurrences of the ! symbol (bang)
* the number of occurrences of the word ‘money’ (money)
* the number of occurrences of the string ‘000’ (n000)
* the number of occurrences of the word ‘make’ (make)
and 1 target variable, which is a factor with levels n not spam, y spam (yesno).

## Problems in the Dataset:
### 0 values
First of all, we noticed that there are many 0 values in the dataset, we have considered, if we treat them as missing values or real values. Because there are just too much 0s, for example in the column "dollar", there are more than 2 times 0 values than other values. Considering the fact that, in many emails there is just no dollar symbol, we decide to take them as real values and do not handle them.

### Missing values, outliers, skewed distribution and new features (continuous variables)
#### Missing values
There is no missing value in our dataset, either explicit nor implicit.
#### Outliers
There are many outliers. Take the column "crl.tot" as an example, we can see from the follwing plot that, the plot has a really long tail and most of the values are between 0-500.

```{r echo=FALSE, out.width = '80%', out.height = '80%', fig.align='center'}
zScores <- function(var){
    mu <- mean(var)
    sd <-  sd(var)
    scores <- (var - mu)/sd
    return(scores)
}

ggplot(spam, aes(crl.tot)) +
          geom_density(na.rm = T,
                       alpha = 0.15,
                       fill  = "royalblue",
                       colour = "grey50") +
          labs(title = "Total length of words in capitals_original") +
          theme(plot.title = element_text(color = "royalblue4", size = 12, face = "bold", hjust = 0.5))

```

#### Treating outliers with Zscore
so we used Zscore and created new column "crl.tot_tr" so that we can better deal with the realtionship between different predicators and the target variable. After getting rid of the outliers, we got the follwing plot:


```{r echo=FALSE, out.width = '80%', out.height = '80%', fig.align='center'}
for (var in c("crl.tot")) {
  x <- zScores(spam[[var]])
  new_var <- paste(var, "tr", sep = "_")
  spam[[new_var]] <- spam[[var]]
  spam[[new_var]][x > 3] <- mean(spam[[var]], na.rm = T) + 
  3*sd(spam[[var]], na.rm = T)
}

ggplot(spam, aes(crl.tot_tr)) +
          geom_density(na.rm = T,
                       alpha = 0.15,
                       fill  = "coral",
                       colour = "grey50") +
          labs(title = "Total length of words in capitals_tr") +
          theme(plot.title = element_text(color = "royalblue4", size = 12, face = "bold", hjust = 0.5))
```

#### Handling with skewed distribution
From the plot above, we know that outliers are removed and we also kept the intactness the original data. To better finish the modelling tasks, we changed the skeness and then we got the follwing plot:
```{r echo=FALSE, out.width = '80%', out.height = '80%', fig.align='center'}
ggplot(spam, aes(log(crl.tot_tr))) +
          geom_density(na.rm = T,
                       alpha = 0.15,
                       fill  = "forestgreen",
                       colour = "grey50") +
          labs(title = "Total length of words in capitals_log") +
          theme(plot.title = element_text(color = "royalblue4", size = 12, face = "bold", hjust = 0.5))

spam$crl.tot_ln <- log(spam$crl.tot_tr) 
```

#### Treating other continuous variables
We used the same methods for other variables and created for each variable a truncated variable and a log variable.

### Treating categoriacal variable
There is only one categorical varaibale in our dataset which is yesno. There is no sparse classes in this variable, so we did not treat it.

```{r echo=FALSE}
for (var in c("dollar", "bang", "money", "n000", "make")) {
  x <- zScores(spam[[var]])
  new_var <- paste(var, "tr", sep = "_")
  spam[[new_var]] <- spam[[var]]
  spam[[new_var]][x > 3] <- mean(spam[[var]], na.rm = T) + 
  3*sd(spam[[var]], na.rm = T)
}
spam$dollar_ln <- log(spam$dollar_tr+0.00001) 
spam$bang_ln <- log(spam$bang_tr+0.0001) 
spam$money_ln <- log(spam$money_tr+0.0001) 
spam$n000_ln <- log(spam$n000_tr+0.0001) 
spam$make_ln <- log(spam$make_tr+0.0001) 
```


### The most valuable insights from EDA
After plotting the relationships between each predicator and the target, it can be easily notice that, generally, the less symbols there are, the more likely that the email is not a spam email. For example, from the plot "The relationship betweeen spam and crl", we can see that, if the eamil is not a spam email, the total length of words in capitals is approximately in the range of 0-400, the average length is about 100. Compared to nonspam eamils, the range of the total length of capitals words in spam emails varies between 0-750. The avarage value is almost 250. It is the same for the reltionships between other predicators and the target.

```{r echo=FALSE}
par(mfrow = c(1,2))
boxplot(crl.tot_tr~yesno, 
        data = spam,
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Total length of words in capitals",
        main = "The Relationship Between Spam and CRL",
        cex.lab  = 0.7,
        cex.main = 0.7)

boxplot(dollar_tr~yesno, 
        data = spam,
        ylim   = c(0,0.7),
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Number of Occurrences of the $ Symbol",
        main = "The Relationship Between Spam and dollar symbol",
        cex.lab  = 0.7,
        cex.main = 0.7)

```


```{r echo=FALSE}
par(mfrow = c(1,2))
boxplot(bang_tr~yesno, 
        data = spam,
        ylim   = c(0,0.7),
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Number of Occurrences of the ! Symbol",
        main = "The Relationship Between Spam and the ! Symbol",
        cex.lab  = 0.7,
        cex.main = 0.7)

boxplot(money_tr~yesno, 
        data = spam,
        ylim   = c(0,0.7),
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Number of Occurrences of the Word money",
        main = "The Relationship Between Spam and the Word money",
        cex.lab  = 0.7,
        cex.main = 0.7)
```


```{r echo=FALSE}
par(mfrow = c(1,2))
boxplot(n000_tr~yesno, 
        data = spam,
        ylim   = c(0,0.7),
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Number of Occurrences of the String 000",
        main = "The Relationship Between Spam and the String 000",
        cex.lab  = 0.7,
        cex.main = 0.7)

boxplot(make_tr~yesno, 
        data = spam,
        ylim   = c(0,0.7),
        names    = c("NO", "YES"),
        col  = c("aquamarine4", "coral2"),
        xlab = "Are They Spam Email?",
        ylab = "Number of Occurrences of the Word make",
        main = "The Relationship Between Spam and Word make",
        cex.lab  = 0.7,
        cex.main = 0.7)
```


Based on this observation, we can make the conclusion that, if there exist a lot of symbols like dollar, bang, 000 or the word 'money', 'make' in an email or there are a lot of capital words in an email, then this email is very likely a spam email.

## Training Models

### Method
Because our models have to classify whether an email is spam or not Logistic Regression and Decision Trees are appropriate methods.
In the first step we thought about the right predictor sets and decided on four different. For all we used the log variables as predictors.

Predictor Set 1 = {money, make, crl.tot} - A set based on occurrence of the different letter sequences.

Predictor Set 2 = {dollar, bang} - A set based on the occurrence of the symbols $ and !.

Predictor Set 3 = {dollar, money, n000} - A set with variables that are directly related to the topic of money. 

Predictor Set 4 = All variables - A set with all variables because all together are high indicators of spam in our opinion.

Before we trained the models we saved 30% of the data as a test set to avoid overfitting. 

We trained four different Logistic Regression Models with one predictor set each. Also, we trained two Ridge Regression Models with predictor set 1 and 2 and two LASSO Regression Models with Predictor Set 3 and 4.
Last but not least we created a Decision Tree with all variables as predictors.

### Best Model
```{r echo=FALSE}
set.seed(777)
#splitting data
train.Index <- sample(1:nrow(spam), round(0.7*nrow(spam)), replace = F) 
  spam.train <- spam[train.Index,] 
  spam.test <- spam[-train.Index,] 
  
  
y.train <- spam.train$yesno
y.test <- spam.test$yesno

y.test.num <- ifelse(y.test == "y", 1,0)
spam.test["yesno_num"] <- c(y.test.num)
```
The model with the highest Accuracy and the lowest Brier Score is the LASSO Regression Model with all variables as predictors.
The R Code for this looks like this: 

```{r, results='hide'}
set.seed(777)
#set feature set
features.all_features <- c("crl.tot_ln" , "dollar_ln" , 
                           "bang_ln" , "money_ln" , "n000_ln" , "make_ln")

#set train and test data
X.train.all_features <- model.matrix( ~ . -1, 
                                data = spam.train[,features.all_features])
X.test.all_features <- model.matrix( ~ . -1, 
                                data = spam.test[, features.all_features])

#fit LASSO Regression Model
all_features.lasso <- glmnet(X.train.all_features, 
                             y.train, alpha= 1, 
                             family = "binomial")

#selecting the optimal lambda with the lowest misclassification error
all_features.lasso_cv <- cv.glmnet(X.train.all_features, 
                                   y.train, alpha = 1, 
                                   type.measure = "class", 
                       lambda = 10^seq(-5, 1, length.out = 100), 
                       family="binomial", nfolds = 10)

#make predictions
pred.all_features.lasso <- as.vector(predict(all_features.lasso, 
                                             newx = X.test.all_features,
                                             type = "response", 
                                        s = all_features.lasso_cv$lambda.min))
```
As the best lambda with the lowest misclassification error we discovered 0.0027.

```{r echo=FALSE, results='hide'}
table(y.test.num)
pred.class.log1 <- ifelse(pred.all_features.lasso > 0.5, 1, 0)
table(pred.class.log1)

Accuracy <- function(pred, real, threshold = 0.5){
  predClass <-  ifelse(pred > threshold, 1, 0)
  acc <- sum(predClass == real) / length(real)
  return(acc)
}
Brier_Score <- function(pred, real){
  RMSE <- sqrt(mean((real - pred)^2))
  return(RMSE)
}

MissClass <- function(pred,real,threshold = 0.5){
   predClass <-  ifelse(pred > threshold, 1, 0)
   right <- sum(predClass == real)
   wrong <- length(pred) - right
   return(wrong)
}

Brier_Score(pred.all_features.lasso, y.test.num)
Accuracy(pred = pred.all_features.lasso, real = y.test.num, threshold = 0.5)
MissClass(pred = pred.all_features.lasso, real = y.test.num, threshold = 0.5)
length(y.test)
```

After it was trained on the training data the model reached an Accuracy of 0.867, a classification Error of 0.133 and a Brier Score of 0.332 

### Evaluation of prediction task
An Accuracy of 0.867 is good but not outstanding. We still have 186 wrong classifications and declare more emails as spam than the other way around. On the one hand, this can be good because more dangerous spam mails can be intercepted. On the other hand, important e-mails could also be mistakenly viewed as spam and then overlooked.

